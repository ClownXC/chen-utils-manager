[node]

all=172.16.71.244,172.16.71.245,172.16.71.246
master=172.16.71.244
worker=172.16.71.244,172.16.71.245,172.16.71.246


[modules]
; common
tool
; spark




# ------------------------------common----------------------------------------
[common]
ssh
java
scala
hosts
hostname
firewalld
selinux


[ssh]
node=all
ssh_user=root
root_password=3494269


[java]
node=all
version=jdk8
# remote
mode=remote
remote_path=https://note3.oss-cn-hangzhou.aliyuncs.com/jdk-8u241-linux-x64.tar.gz
; mode=local
; pkg_path=/root/jdk-8u241-linux-x64.tar.gz
home="/usr/local/opt/java"

[scala]
node=all
version=2.12
# version=2.11
# download
# default
; mode=local
mode=remote
remote_url=https://note3.oss-cn-hangzhou.aliyuncs.com/scala-2.12.17.tgz
; remote_path=https://note3.oss-cn-hangzhou.aliyuncs.com/scala-2.11.8.tgz
pkg_path="/root"
home="/usr/local/opt/scala"



[hosts]
node=all
worker_=worker...
master=master

[hostname]
mode=hosts

[firewalld]
node=all
;hello
[selinux]
node=all





# ------------------------------tool----------------------------------------

[tool]
vim
oh-my-zsh
ansible
git
lnav
trash



[oh-my-zsh]
node=all
plugins=sublime,z,history-substring-search,git,zsh-autosuggestions,zsh-syntax-highlighting,sudo,web-search,last-working-dir
theme=ys

[vim]
node=all
; node=all,172.16.71.232
; plugins=""
; theme=""
[ansible]
node=all









# ------------------------------spark----------------------------------------
[spark]
master=master
worker=worker
pkg_path=/root
spark_home=/usr/local/opt/spark
deploy_mode=standalone
install_mode=remote
spark_version=3.3.1
hadoop_version=hadoop2
# $JAVA_HOME
java_home=/usr/local/opt/java/jdk1.8.0_241









# ------------------------------supervior----------------------------------------

[supervior]






